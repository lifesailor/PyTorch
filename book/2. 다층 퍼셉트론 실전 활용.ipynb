{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 와인 분류하기 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사전 학습 알고리즘으로는 자기부호화기가 유명하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화 기법\n",
    "\n",
    "1. 가중치 감쇠\n",
    "2. 배치 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyTorch\n",
    "import torch # tensor\n",
    "from torch.autograd import Variable # 자동미분\n",
    "import torch.nn as nn # 신경망구성\n",
    "import torch.nn.functional as F # 신경망에 사용되는 함수 정의\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# scikit-learn \n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "wine.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = wine.data[0:130]\n",
    "wine_target = wine.target[0:130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.179e+01, 2.130e+00, 2.780e+00, 2.850e+01, 9.200e+01, 2.130e+00,\n",
       "         2.240e+00, 5.800e-01, 1.760e+00, 3.000e+00, 9.700e-01, 2.440e+00,\n",
       "         4.660e+02],\n",
       "        [1.237e+01, 1.630e+00, 2.300e+00, 2.450e+01, 8.800e+01, 2.220e+00,\n",
       "         2.450e+00, 4.000e-01, 1.900e+00, 2.120e+00, 8.900e-01, 2.780e+00,\n",
       "         3.420e+02],\n",
       "        [1.204e+01, 4.300e+00, 2.380e+00, 2.200e+01, 8.000e+01, 2.100e+00,\n",
       "         1.750e+00, 4.200e-01, 1.350e+00, 2.600e+00, 7.900e-01, 2.570e+00,\n",
       "         5.800e+02]]), array([1, 1, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data[-3:], wine_target[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(wine_data, wine_target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 26\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X), len(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 텐서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.from_numpy(ndarray)\n",
    "# Numpy 배열을 텐서로 변환한다.\n",
    "\n",
    "train_X = torch.from_numpy(train_X).float()\n",
    "train_Y = torch.from_numpy(train_Y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([104, 13]), torch.Size([104]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = torch.from_numpy(test_X).float()\n",
    "test_Y = torch.from_numpy(test_Y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([26, 13]), torch.Size([26]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 설명변수와 목적변수를 합침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 12.5100,   1.7300,   1.9800,  20.5000,  85.0000,   2.2000,   1.9200,\n",
      "          0.3200,   1.4800,   2.9400,   1.0400,   3.5700, 672.0000]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "# torch.utils.data.TensorDataset(data_tensor, target_tensor)\n",
    "# 설명변수와 목적변수를 합쳐 인덱스를 붙이고 하나의 데이터 집합으로 만든다.\n",
    "\n",
    "train = TensorDataset(train_X, train_Y)\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 집합을 원하는 크기의 미니배치로 나누어 읽어들인다.\n",
    "train_loader = DataLoader(train, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataset(Dataset): 읽어들일 데이터 집합\n",
    "- batch_size: 배치 크기\n",
    "- shuffle: 각 에폭마다 데이터 셔플링 여부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 신경망 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 96)\n",
    "        self.fc2 = nn.Linear(96, 96)\n",
    "        self.fc3 = nn.Linear(96, 96)\n",
    "        self.fc4 = nn.Linear(96, 96)\n",
    "        self.fc5 = nn.Linear(96, 96)\n",
    "        self.fc6 = nn.Linear(96, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Module\n",
    "# 모든 신경망의 갑ㄴ이 된다.\n",
    "\n",
    "# torch.nn.Linear(in_features, out_features, bias=True)\n",
    "\n",
    "# torch.nn.functional.relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모형 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lifesailor/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/lifesailor/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(2.4700)\n",
      "100 tensor(1.8214)\n",
      "150 tensor(1.6348)\n",
      "200 tensor(1.4889)\n",
      "250 tensor(1.7697)\n",
      "300 tensor(1.2800)\n"
     ]
    }
   ],
   "source": [
    "# 오차 함수 객체\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화 객체\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 시작\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    \n",
    "    # 분할해 둔 데이터를 꺼내옴\n",
    "    for train_x, train_y in train_loader:\n",
    "        \n",
    "        # 계산 그래프 구성 \n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        \n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 순전파 계산\n",
    "        output = model(train_x)\n",
    "        \n",
    "        # 오차 계산\n",
    "        loss = criterion(output, train_y)\n",
    "        \n",
    "        # 역전파 계산\n",
    "        loss.backward()\n",
    "        \n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data[0]\n",
    "        \n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(epoch + 1, total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 손글씨 이미지 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lifesailor/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/lifesailor/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'COL_NAMES': ['label', 'data'],\n",
       " 'target': array([0., 0., 0., ..., 9., 9., 9.]),\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = datasets.fetch_mldata('MNIST original', data_home='./data/')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data = mnist.data / 255\n",
    "mnist_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist_data[0].reshape(28, 28), cmap=cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 9., 9., 9.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_label = mnist.target\n",
    "mnist_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 5000\n",
    "test_size = 500\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = model_selection.train_test_split(mnist_data, mnist_label, \n",
    "                                                                    train_size=train_size,\n",
    "                                                                    test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 784])\n",
      "torch.Size([5000])\n"
     ]
    }
   ],
   "source": [
    "# numpy 배열을 텐서로 변환한다.\n",
    "train_X = torch.from_numpy(train_X).float()\n",
    "train_Y = torch.from_numpy(train_Y).long()\n",
    "\n",
    "test_X = torch.from_numpy(test_X).float()\n",
    "test_Y = torch.from_numpy(test_Y).long()\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510, 0.4745,\n",
      "        0.4745, 0.7490, 0.9686, 0.5216, 0.0745, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.9451,\n",
      "        0.9882, 0.9882, 0.9922, 0.9882, 0.9882, 0.9490, 0.4196, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0784, 0.7412,\n",
      "        0.9882, 0.9882, 0.9882, 0.9922, 0.9882, 0.9882, 0.9882, 0.9608, 0.6980,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863, 0.7333,\n",
      "        0.9882, 0.9882, 0.9882, 0.9882, 0.9922, 0.9882, 0.9882, 0.9882, 0.9882,\n",
      "        0.7765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4039,\n",
      "        0.9882, 0.9882, 0.9882, 0.9725, 0.4510, 0.2078, 0.5333, 0.9882, 0.9882,\n",
      "        0.9882, 0.7765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.7843, 0.9882, 0.9882, 0.9882, 0.8235, 0.0000, 0.0000, 0.4196, 0.9882,\n",
      "        0.9882, 0.9882, 0.7765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7843, 0.9882, 0.9882, 0.8314, 0.1294, 0.0000, 0.0000, 0.7765,\n",
      "        0.9882, 0.9882, 0.9882, 0.6941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.7843, 0.9882, 0.9882, 0.6902, 0.0000, 0.0000, 0.3020,\n",
      "        0.9686, 0.9882, 0.9882, 0.9882, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.1843, 0.9020, 0.9882, 0.9882, 0.5765, 0.0000, 0.0000,\n",
      "        0.5020, 0.9882, 0.9882, 0.9882, 0.8353, 0.1098, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.3176, 0.9882, 0.9882, 0.9882, 0.6353, 0.0314,\n",
      "        0.5216, 0.9922, 0.9882, 0.9882, 0.9882, 0.7255, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7882, 0.9922, 0.9922, 0.9922,\n",
      "        0.9922, 0.9922, 1.0000, 0.9922, 0.9922, 0.9922, 0.2078, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7843, 0.9882, 0.9882,\n",
      "        0.9882, 0.9882, 0.9882, 0.9922, 0.9882, 0.9882, 0.9882, 0.2078, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9882,\n",
      "        0.9882, 0.9882, 0.9882, 0.9882, 0.9922, 0.9882, 0.9882, 0.9882, 0.2078,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431,\n",
      "        0.2627, 0.6745, 0.6745, 0.8549, 0.9882, 0.9922, 0.9882, 0.9882, 0.9882,\n",
      "        0.6471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.1608, 0.9882, 0.9922, 0.9882, 0.9882,\n",
      "        0.9882, 0.7255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.9882, 0.9922, 0.9882,\n",
      "        0.9882, 0.9882, 0.9216, 0.1922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.9882, 0.9922,\n",
      "        0.9882, 0.9882, 0.9882, 0.9882, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.9882,\n",
      "        0.9922, 0.9882, 0.9882, 0.9882, 0.9882, 0.2588, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510,\n",
      "        0.9647, 0.9922, 0.9882, 0.9882, 0.9882, 0.8353, 0.1098, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.2471, 0.9922, 0.9882, 0.9882, 0.8196, 0.3451, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000]), tensor(8))\n"
     ]
    }
   ],
   "source": [
    "# 설명 변수와 목적 변수를 합쳐서 train이라는 이름으로 훈련 데이터 객체를 만든다.\n",
    "train = TensorDataset(train_X, train_Y)\n",
    "print(train[0])\n",
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "# 데이터 집합을 원하는 크기의 미니배치로 나누어 읽어 들인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 128)\n",
    "        self.fc6 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        \n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc6(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lifesailor/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/lifesailor/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 tensor(0.0498)\n",
      "200 tensor(0.0306)\n",
      "300 tensor(0.0274)\n",
      "400 tensor(0.0636)\n",
      "500 tensor(0.0255)\n",
      "600 tensor(0.0140)\n",
      "700 tensor(0.0244)\n",
      "800 tensor(0.0158)\n",
      "900 tensor(0.0133)\n",
      "1000 tensor(0.0250)\n"
     ]
    }
   ],
   "source": [
    "# 오차함수 객체\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화를 담당할 객체\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "    \n",
    "    # 분할해 둔 데이터를 꺼내옴\n",
    "    for train_x, train_y in train_loader:\n",
    "        \n",
    "        # compose calculation graph\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward\n",
    "        output = model(train_x)\n",
    "        \n",
    "        # loss\n",
    "        loss = criterion(output, train_y)\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # update weight\n",
    "        optimizer.step()\n",
    "        \n",
    "        # cumulative loss\n",
    "        total_loss += loss.data[0]\n",
    "        \n",
    "    if (epoch+1)% 100 == 0:\n",
    "        print(epoch + 1, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.CrossEntropy\n",
    "# 교차 엔트로피 함수를 구현한 클래스다.\n",
    "\n",
    "# torch.optim.SGD\n",
    "# 확률적 경사하강법을 구현한 클래스다.\n",
    "\n",
    "# torch.autograd.Variable(data)\n",
    "# 텐서를 래핑하고 계산 과정을 기록한다.\n",
    "\n",
    "# torch.autograd.backward(variables)\n",
    "# 경사의 합을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lifesailor/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# compose calculation graph\n",
    "test_x, test_y = Variable(test_X), Variable(test_Y)\n",
    "result = torch.max(model(test_x).data, 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
