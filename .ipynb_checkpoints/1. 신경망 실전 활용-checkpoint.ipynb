{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. torch: 텐서를 생성하는 라이브러리\n",
    "2. torch.autograd: 자동 미분 기능을 제공하는 라이브러리\n",
    "3. torch.nn: 신경망을 생성하는 라이브러리\n",
    "4. torch.multiprocessing: 병렬처리 기능을 제공하는 라이브러리\n",
    "5. torch.utils: 데이터 조작 등 유틸리티 기능\n",
    "6. torch.legacy: Torch로부터 포팅해온 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 학습 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyTorch\n",
    "import torch # tensor\n",
    "from torch.autograd import Variable # 자동미분\n",
    "import torch.nn as nn # 신경망구성\n",
    "import torch.nn.functional as F # 신경망에 사용되는 함수 정의\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# scikit-learn \n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "wine.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = wine.data[0:130]\n",
    "wine_target = wine.target[0:130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.179e+01, 2.130e+00, 2.780e+00, 2.850e+01, 9.200e+01, 2.130e+00,\n",
       "         2.240e+00, 5.800e-01, 1.760e+00, 3.000e+00, 9.700e-01, 2.440e+00,\n",
       "         4.660e+02],\n",
       "        [1.237e+01, 1.630e+00, 2.300e+00, 2.450e+01, 8.800e+01, 2.220e+00,\n",
       "         2.450e+00, 4.000e-01, 1.900e+00, 2.120e+00, 8.900e-01, 2.780e+00,\n",
       "         3.420e+02],\n",
       "        [1.204e+01, 4.300e+00, 2.380e+00, 2.200e+01, 8.000e+01, 2.100e+00,\n",
       "         1.750e+00, 4.200e-01, 1.350e+00, 2.600e+00, 7.900e-01, 2.570e+00,\n",
       "         5.800e+02]]), array([1, 1, 1]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data[-3:], wine_target[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(wine_data, wine_target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 26\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X), len(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 텐서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.from_numpy(ndarray)\n",
    "# Numpy 배열을 텐서로 변환한다.\n",
    "\n",
    "train_X = torch.from_numpy(train_X).float()\n",
    "train_Y = torch.from_numpy(train_Y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([104, 13]), torch.Size([104]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = torch.from_numpy(test_X).float()\n",
    "test_Y = torch.from_numpy(test_Y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([26, 13]), torch.Size([26]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 설명변수와 목적변수를 합침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 12.3700,   1.1700,   1.9200,  19.6000,  78.0000,   2.1100,   2.0000,\n",
      "          0.2700,   1.0400,   4.6800,   1.1200,   3.4800, 510.0000]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "# torch.utils.data.TensorDataset(data_tensor, target_tensor)\n",
    "# 설명변수와 목적변수를 합쳐 인덱스를 붙이고 하나의 데이터 집합으로 만든다.\n",
    "\n",
    "train = TensorDataset(train_X, train_Y)\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 집합을 원하는 크기의 미니배치로 나누어 읽어들인다.\n",
    "train_loader = DataLoader(train, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataset(Dataset): 읽어들일 데이터 집합\n",
    "- batch_size: 배치 크기\n",
    "- shuffle: 각 에폭마다 데이터 셔플링 여부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 신경망 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력층 노드 수 13개, 중간층 노드 수 96개, 출력 층 노드 수 2개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 구성\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 생성자 메서드에서는 네트워크의 구조를 설정한다.\n",
    "        self.fc1 = nn.Linear(13, 96)\n",
    "        self.fc2 = nn.Linear(96, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # forward 메서에서는 활성화 함수를 정의한다.\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "# 인스턴스 생성\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Linear(in_features, out_features, bias=True)\n",
    "# 입력 데이터에 대한 선형 변환을 계산한다.\n",
    "\n",
    "# torch.nn.functional.relu(input)\n",
    "# Relu 함수를 구현한 함수다\n",
    "\n",
    "# torch.nn.functional.log_softmax(input)\n",
    "# softmax 함수를 구현한 함수다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모형 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/base-workspace/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/envs/base-workspace/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(4.8509)\n",
      "100 tensor(4.8537)\n",
      "150 tensor(4.8540)\n",
      "200 tensor(4.8499)\n",
      "250 tensor(4.8522)\n",
      "300 tensor(4.8549)\n"
     ]
    }
   ],
   "source": [
    "# 오차 함수 객체\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화 객체\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 시작\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    \n",
    "    # 분할해 둔 데이터를 꺼내옴\n",
    "    for train_x, train_y in train_loader:\n",
    "        \n",
    "        # 계산 그래프 구성 \n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        \n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 순전파 계산\n",
    "        output = model(train_x)\n",
    "        \n",
    "        # 오차 계산\n",
    "        loss = criterion(output, train_y)\n",
    "        \n",
    "        # 역전파 계산\n",
    "        loss.backward()\n",
    "        \n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data[0]\n",
    "        \n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(epoch + 1, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.CrossEntropy\n",
    "# criterion: 오차 함수 인스턴스\n",
    "\n",
    "# torch.optim.SGD(params)\n",
    "# 확률적 경사하강법\n",
    "\n",
    "# torch.autograd.Variable(data)\n",
    "# 텐서를 래핑하고 계산 과정을 기록한다.\n",
    "\n",
    "# torch.autograd.backward(variables)\n",
    "# 경사의 합을 구한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/base-workspace/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6923076923076923"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 그래프 구성\n",
    "test_x, test_y = Variable(test_X), Variable(test_Y)\n",
    "\n",
    "# 출력이 0 혹은 1이 되게함\n",
    "result = torch.max(model(test_x).data, 1)[1]\n",
    "\n",
    "# 모형 정확도 측정\n",
    "accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
